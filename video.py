import cv2
from fastapi import FastAPI
from fastapi.responses import StreamingResponse, HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from ultralytics import YOLO

import mediapipe as mp
import cv2

app = FastAPI()
app.mount("/static", StaticFiles(directory="static"), name="static")

# -------------------------------
# Load YOLO model (TensorRT / ONNX / PT / TorchScript)
# -------------------------------
model_name = 'yolov8n'
dataset_name = 'AI231_dataset'
format = 'onnx'

format_extension = {
    'pytorch': 'pt',
    'onnx': 'onnx',
    'tensorrt': 'engine',
    'torchscript': 'torchscript'
}

# model = YOLO(f"../AI231/AI231_dataset/runs/{model_name}-{dataset_name}-augmented/weights/best.{format_extension[format]}")
model = YOLO(f"./models/best.{format_extension[format]}")
print(f"Loaded {model_name} model in {format} format")


# -------------------------------
# POS Item List
# -------------------------------
ITEMS = {
    0:  {"name": "coffee_nescafe", "price": 5},
    1:  {"name": "coffee_kopiko", "price": 5},
    2:  {"name": "lucky-me-pancit-canton", "price": 10},
    3:  {"name": "Coke-in-can", "price": 50},
    4:  {"name": "alaska_milk", "price": 120},
    5:  {"name": "Century-Tuna", "price": 35},
    6:  {"name": "VCut-Spicy-Barbeque", "price": 30},
    7:  {"name": "Selecta-Cornetto", "price": 25},
    8:  {"name": "nestleyogurt", "price": 75},
    9:  {"name": "Femme-Bathroom-Tissue", "price": 130},
    10: {"name": "maya-champorado", "price": 25},
    11: {"name": "jnj-potato-chips", "price": 30},
    12: {"name": "Nivea-Deodorant", "price": 150},
    13: {"name": "UFC-Canned-Mushroom", "price": 45},
    14: {"name": "Libbys-Vienna-Sausage-can", "price": 40},
    15: {"name": "Stik-O", "price": 60},
    16: {"name": "nissin_cup_noodles", "price": 35},
    17: {"name": "dewberry-strawberry", "price": 60},
    18: {"name": "Smart-C", "price": 40},
    19: {"name": "pineapple-juice-can", "price": 35},
    20: {"name": "nestle_chuckie", "price": 50},
    21: {"name": "Delight-Probiotic-Drink", "price": 45},
    22: {"name": "Summit-Drinking-Water", "price": 15},
    23: {"name": "almond_milk", "price": 85},
    24: {"name": "Piknik", "price": 30},
    25: {"name": "Rambutan", "price": 15},
    26: {"name": "head&shoulders_shampoo", "price": 110},
    27: {"name": "irish-spring-soap", "price": 130},
    28: {"name": "c2_na_green", "price": 35},
    29: {"name": "colgate_toothpaste", "price": 150},
    30: {"name": "555-sardines-tomato", "price": 35},
    31: {"name": "meadows_truffle_chips", "price": 40},
    32: {"name": "double-black", "price": 400},
    33: {"name": "NongshimCupNoodles", "price": 35},
}

# -------------------------------
# Global state for POS and inference status
# -------------------------------
pos_items = {}
running = False
last_count = 0

# -------------------------------
# Mediapipe Hands for gesture recognition
# -------------------------------

mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1)
mp_draw = mp.solutions.drawing_utils

def is_open_hand(landmarks):
    # finger tips indices
    tips = [4, 8, 12, 16, 20]

    open_fingers = 0
    for tip in tips[1:]:   # ignore thumb for now
        if landmarks[tip].y < landmarks[tip - 2].y:  # fingertip above knuckle
            open_fingers += 1

    return open_fingers >= 4   # All 4 fingers extended

# ============================================================
#   BASIC CAMERA STREAM (NO INFERENCE)
# ============================================================
def generate_frames():
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    if not cap.isOpened():
        print("âŒ Could not open camera")
        return

    try:
        while True:
            ok, frame = cap.read()
            if not ok:
                continue

            ok, buffer = cv2.imencode(".jpg", frame)
            if not ok:
                continue

            yield (
                b"--frame\r\n"
                b"Content-Type: image/jpeg\r\n\r\n" +
                buffer.tobytes() +
                b"\r\n"
            )
    finally:
        cap.release()


# ============================================================
#   INFERENCE STREAM (YOLO)
# ============================================================
def generate_inference_frames():
    global running, pos_items
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    if not cap.isOpened():
        print("âŒ Could not open camera")
        return

    try:
        while True:
            ok, frame = cap.read()
            if not ok:
                continue

            if not running:
                results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                if results.multi_hand_landmarks:
                    lm = results.multi_hand_landmarks[0].landmark
                    if is_open_hand(lm):
                        print("ðŸ–ï¸ Open hand detected â†’ Starting inference...")
                        running = True

            if running:
                results = model(frame, verbose=False)
                annotated = results[0].plot()

                # Add detected items with conf >= 0.9
                for box in results[0].boxes:
                    cls = int(box.cls[0])
                    conf = float(box.conf[0])
                    if conf >= 0.85:
                        item = ITEMS.get(cls)
                        if item:
                            name = item["name"]
                            price = item["price"]
                            if name in pos_items:
                                pos_items[name]["qty"] += 1
                            else:
                                pos_items[name] = {"qty": 1, "unit_price": price}
                            running = False   # stop after high confidence detection

                ok, buffer = cv2.imencode(".jpg", annotated)
                if not ok:
                    continue
            else:
                # show normal frame if not running
                ok, buffer = cv2.imencode(".jpg", frame)
                if not ok:
                    continue

            yield (
                b"--frame\r\n"
                b"Content-Type: image/jpeg\r\n\r\n" +
                buffer.tobytes() +
                b"\r\n"
            )
    finally:
        cap.release()


# ============================================================
#   ROUTES
# ============================================================
@app.get("/", response_class=HTMLResponse)
def index():
    html = """
    <!doctype html>
    <html>

    <head>
      <meta charset="utf-8" />
      <meta name="viewport" content="width=device-width,initial-scale=1" />
      <title>Camera POS</title>
      <style>
        body { display:flex; margin:0; padding:0; height:100vh; background:black; color:white; }
        #cam { flex: 0 0 60%; object-fit: cover; width: 100%; height: 100%; }
        #pos { flex: 0 0 40%; padding: 10px; overflow: auto; background: #111; }
        table { width:100%; border-collapse: collapse; }
        th, td { border:1px solid #555; padding:5px; text-align:left; }
        button { padding:10px 20px; font-size:16px; margin-bottom:10px; }
      </style>
    </head>

    <body>
      <div>
        <img id="cam" src="/inference" alt="Camera stream">
      </div>
      <div id="pos">
        <button onclick="startInference()">Start</button>
        <h2>Items:</h2>
        <table id="pos_table">
          <tr><th>Qty</th><th>Name</th><th>Unit Price (â‚±)</th><th>Total Price (â‚±)</th></tr>
        </table>
        <h3>Grand Total: â‚±<span id="grand_total">0</span></h3>
      </div>

      <audio id="beep_sound" src="/static/beep.mp3"></audio>

      <script>
        let beep_unlocked = false;

        function startInference() {
          fetch('/start');
        }

        // Unlock beep sound on first user interaction
        if (!beep_unlocked) {
        const beep = document.getElementById('beep_sound');
        beep.play().catch(() => {});  // play once to unlock
        beep.pause();
        beep.currentTime = 0;
        beep_unlocked = true;
        }

        async function updatePOS() {
          const response = await fetch('/pos_items');
          const data = await response.json();
          const table = document.getElementById('pos_table');

          // Clear table except header
          table.innerHTML = '<tr><th>Qty</th><th>Name</th><th>Unit Price (â‚±)</th><th>Total Price (â‚±)</th></tr>';

          // Add items
          for (const item of data.items) {
            const row = table.insertRow();
            row.insertCell(0).textContent = item.qty;
            row.insertCell(1).textContent = item.name;
            row.insertCell(2).textContent = item.unit_price;
            row.insertCell(3).textContent = item.total_price;
          }

          // Update grand total
          document.getElementById('grand_total').textContent = data.grand_total;
          
            // Play beep if new item detected
          if (data.new_item && beep_unlocked) {
            document.getElementById('beep_sound').play();
          }
        }

        setInterval(updatePOS, 500);
      </script>
    </body>
    </html>
    """
    return html

@app.get("/pos_items")
def get_pos_items():
    # Calculate total per item and grand total
    global pos_items, last_count
    items_list = []
    grand_total = 0
    total_qty = 0
    for name, data in pos_items.items():
        total_price = data["qty"] * data["unit_price"]
        grand_total += total_price
        total_qty += data["qty"]
        items_list.append({
            "qty": data["qty"],
            "name": name,
            "unit_price": data["unit_price"],
            "total_price": total_price
        })

    new_item_detected = total_qty > last_count
    last_count = total_qty

    return JSONResponse({"items": items_list, "grand_total": grand_total, "new_item": new_item_detected})

# Start inference route
@app.get("/start")
def start_inference():
    global running, pos_items, last_count
    running = True
    return {"status": "inference started"}

@app.get("/video_feed")
def video_feed():
    return StreamingResponse(
        generate_frames(),
        media_type="multipart/x-mixed-replace; boundary=frame"
    )

@app.get("/inference")
def inference_feed():
    return StreamingResponse(
        generate_inference_frames(),
        media_type="multipart/x-mixed-replace; boundary=frame"
    )
